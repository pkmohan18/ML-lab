{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c92b32b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'w': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]},\n",
      "  {'w': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}],\n",
      " [{'w': [0.651592972722763, 0.7887233511355132, 0.0938595867742349]},\n",
      "  {'w': [0.02834747652200631, 0.8357651039198697, 0.43276706790505337]}]]\n",
      "epoch=0, lrate=0.500,error=5.440\n",
      "epoch=1, lrate=0.500,error=5.333\n",
      "epoch=2, lrate=0.500,error=5.353\n",
      "epoch=3, lrate=0.500,error=5.378\n",
      "epoch=4, lrate=0.500,error=5.391\n",
      "epoch=5, lrate=0.500,error=5.394\n",
      "epoch=6, lrate=0.500,error=5.392\n",
      "epoch=7, lrate=0.500,error=5.388\n",
      "epoch=8, lrate=0.500,error=5.382\n",
      "epoch=9, lrate=0.500,error=5.376\n",
      "epoch=10, lrate=0.500,error=5.370\n",
      "epoch=11, lrate=0.500,error=5.363\n",
      "epoch=12, lrate=0.500,error=5.356\n",
      "epoch=13, lrate=0.500,error=5.350\n",
      "epoch=14, lrate=0.500,error=5.343\n",
      "epoch=15, lrate=0.500,error=5.337\n",
      "epoch=16, lrate=0.500,error=5.330\n",
      "epoch=17, lrate=0.500,error=5.323\n",
      "epoch=18, lrate=0.500,error=5.317\n",
      "epoch=19, lrate=0.500,error=5.310\n",
      "[{'delta': 0.007075129766006115,\n",
      "  'output': 0.8575212514344961,\n",
      "  'w': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]},\n",
      " {'delta': 0.015529678943784878,\n",
      "  'output': 0.9173465422684997,\n",
      "  'w': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}]\n",
      "[{'delta': -0.10272845214815102,\n",
      "  'output': 0.4213414492550106,\n",
      "  'w': [-0.1506943575429818, -0.40884520589829626, -0.3285441795150825]},\n",
      " {'delta': 0.10139414318489678,\n",
      "  'output': 0.5829460290261248,\n",
      "  'w': [0.5065408521155171, 1.7000377856935267, 0.03918328638995719]}]\n"
     ]
    }
   ],
   "source": [
    "from random import random,seed,randint\n",
    "from pprint import pprint\n",
    "def initialize(n_inputs,n_hidden,n_output):\n",
    "    network=[]\n",
    "    hidden_layer=[{'w':[random() for i in range(n_inputs+1)]} for i in range(n_hidden)] #Initialize Weights and Biases for hidden layers\n",
    "    network.append(hidden_layer)\n",
    "    output_layer=[{'w':[random() for i in range(n_hidden+1)]} for i in range(n_output)] #Initialize Weights and Biases for output layer\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    "def activate(w,i):\n",
    "    activation=w[-1] #Bias value is -1\n",
    "    for x in range(len(w)-1):\n",
    "        activation+=w[x]*i[x] #WX similar to WiXi + Bias ie activation=activation + Wixi\n",
    "        return activation #WX+B\n",
    "from math import exp\n",
    "def sigmoid(a):\n",
    "    return 1/(1+exp(-a))\n",
    "def forward_prop(network,row):\n",
    "    inputs=row\n",
    "    for layer in network:\n",
    "        new_inputs=[]\n",
    "        for neuron in layer:\n",
    "            activation=activate(neuron['w'],inputs) #Compute Activations\n",
    "            neuron['output']=sigmoid(activation) #Compute Sigmoid\n",
    "            new_inputs.append(neuron['output']) #Adds it to the output layer\n",
    "        inputs=new_inputs #new_inputs values now becomes the input\n",
    "    return inputs\n",
    "def sigmoid_derivative(output):\n",
    "    return output * (1-output) #Derivative of 1/(1+e^-x)\n",
    "def backprop(network,expected): #expected is our expected output value we'd use to compute the error\n",
    "    for i in reversed(range(len(network))): #Prints the list ie \"Network\" in reversed order\n",
    "        layer=network[i] #network contains what? see below\n",
    "        errors=[] #initialize error values to an empty list\n",
    "        if i!=len(network)-1: #Output Layer\n",
    "            for j in range(len(layer)):\n",
    "                error=0 #Assign error values to 0\n",
    "                for neuron in network[i+1]:\n",
    "                    error+=(neuron['w'][j]*neuron['delta'])#Calculates and Updates the error\n",
    "                errors.append(error)\n",
    "        else:\n",
    "                for j in range(len(layer)):\n",
    "                    neuron=layer[j]\n",
    "                    errors.append(expected[j]-neuron['output']) #Calculates and appends the errors\n",
    "        for j in range(len(layer)):\n",
    "                neuron=layer[j]\n",
    "                neuron['delta']=errors[j]*sigmoid_derivative(neuron['output']) #Compute Gradients\n",
    "def update_weights(network,row,lrate): #Gradient Descent\n",
    "    for i in range(len(network)):\n",
    "        inputs=row[:-1] #Takes all except last row \n",
    "        if i!=0: \n",
    "            inputs=[neuron['output'] for neuron in network[i-1]]\n",
    "            for neuron in network[i]:\n",
    "                for j in range(len(inputs)):\n",
    "                    neuron['w'][j]+=lrate*neuron['delta']*inputs[j] #Weights update similar to w5 + n*Edy*xi\n",
    "                    neuron['w'][-1]+=lrate*neuron['delta'] #Bias is -1 and its updated\n",
    "def train_network(network,train,lrate,epochs,n_output):\n",
    "    for epoch in range(epochs):\n",
    "        sum_err=0\n",
    "        for row in train:\n",
    "            outputs=forward_prop(network,row)\n",
    "            expected=[0 for i in range(n_output)]\n",
    "            expected[row[-1]]=1\n",
    "            sum_err+=sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])#Computes the error\n",
    "            backprop(network,expected)#Calls backpropagation\n",
    "            update_weights(network,row,lrate)#Finally weights are updated\n",
    "        print('epoch=%d, lrate=%.3f,error=%.3f'%(epoch,lrate,sum_err))\n",
    "seed(1)\n",
    "data=[[2.7810836,2.550537003,0],\n",
    "      [1.465489372,2.362125076,0],\n",
    "      [3.396561688,4.400293529,0],\n",
    "      [1.38807019,1.850220317,0],\n",
    "      [3.06407232,3.005305973,0],\n",
    "      [7.627531214,2.759262235,1],\n",
    "      [5.332441248,2.088626775,1],\n",
    "      [6.922596716,1.77106367,1],\n",
    "      [8.675418651,-0.242068655,1],\n",
    "      [7.673756466,3.508563011,1]] #This dataset contain 2 input inits and 1 output unit\n",
    "n_inputs=len(data[0])-1\n",
    "n_outputs=len(set(row[-1] for row in data))\n",
    "network=initialize(n_inputs,2,n_outputs)\n",
    "pprint(network)\n",
    "train_network(network,data,0.5,20,n_outputs)\n",
    "for layer in network:\n",
    "    pprint(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb932c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
